from fastapi import FastAPI, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from contextlib import asynccontextmanager
import torch
import time
import os
from .routes.health import router as health_router
from .routes.analyze import router as analyze_router
from .routes.convert import router as convert_router
from .routes.monitoring import router as monitoring_router
from .routes.welcome import router as welcome_router
from .utils.metrics_store import add_request_metric
from analyzer.config import MODEL_PATH

# å…¨å±€æ¨¡å‹å˜é‡
MODEL = None

@asynccontextmanager
async def lifespan(app: FastAPI):
    """åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†ï¼ŒåŒ…å«æ¨¡å‹é¢„çƒ­"""
    global MODEL
    
    # å¯åŠ¨æ—¶åŠ è½½æ¨¡å‹
    print("ğŸš€ æ­£åœ¨å¯åŠ¨ GolfTracker æœåŠ¡...")
    try:
        # æ£€æŸ¥ CUDA å¯ç”¨æ€§
        cuda_available = torch.cuda.is_available()
        print(f"ğŸ”§ CUDA å¯ç”¨æ€§: {cuda_available}")
        
        if cuda_available:
            print(f"ğŸ¯ GPU è®¾å¤‡: {torch.cuda.get_device_name(0)}")
            print(f"ğŸ’¾ GPU å†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
        
        # åŠ è½½æ¨¡å‹ï¼ˆå»¶è¿ŸåŠ è½½ï¼Œè¿™é‡Œåªåšé¢„çƒ­ï¼‰
        print("ğŸ“¦ æ­£åœ¨é¢„çƒ­æ¨¡å‹...")
        from ultralytics import YOLO
        MODEL = YOLO(MODEL_PATH)
        
        # æ¨¡å‹é¢„çƒ­ï¼šè¿è¡Œä¸€æ¬¡å‡çš„æ¨ç†ç¡®ä¿GPUä¸Šä¸‹æ–‡å°±ç»ª
        if cuda_available:
            MODEL.to("cuda")
            if hasattr(MODEL, "model") and hasattr(MODEL.model, "half"):
                MODEL.model.half = True
        else:
            MODEL.to("cpu")
            if hasattr(MODEL, "model") and hasattr(MODEL.model, "half"):
                MODEL.model.half = False
        
        # è¿è¡Œé¢„çƒ­æ¨ç†
        import numpy as np
        dummy_image = np.zeros((480, 640, 3), dtype=np.uint8)
        MODEL.predict(
            source=dummy_image,
            verbose=False,
            device="cuda" if cuda_available else "cpu",
            imgsz=480,
            conf=0.01,
            iou=0.7,
            max_det=10,
            agnostic_nms=False,
            augment=False,
        )
        
        print("âœ… æ¨¡å‹é¢„çƒ­å®Œæˆï¼ŒæœåŠ¡å·²å°±ç»ª")
        
    except Exception as e:
        print(f"âš ï¸ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        MODEL = None
    
    yield
    
    # å…³é—­æ—¶æ¸…ç†èµ„æº
    print("ğŸ›‘ æ­£åœ¨å…³é—­ GolfTracker æœåŠ¡...")
    if MODEL is not None:
        del MODEL
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
    print("âœ… æœåŠ¡å·²å…³é—­")


def create_app() -> FastAPI:
    app = FastAPI(
        title="GolfTracker Service", 
        version="0.1.0",
        lifespan=lifespan
    )
    
    # æ·»åŠ  CORS ä¸­é—´ä»¶æ”¯æŒæœ¬åœ°æµ‹è¯•
    app.add_middleware(
        CORSMiddleware,
        allow_origins=["*"],  # åœ¨ç”Ÿäº§ç¯å¢ƒä¸­åº”è¯¥è®¾ç½®å…·ä½“çš„åŸŸå
        allow_credentials=True,
        allow_methods=["*"],
        allow_headers=["*"],
    )
    
    # æ·»åŠ è¯·æ±‚è·Ÿè¸ªä¸­é—´ä»¶
    @app.middleware("http")
    async def track_requests(request: Request, call_next):
        """ä¸­é—´ä»¶ï¼šè·Ÿè¸ªè¯·æ±‚ç»Ÿè®¡"""
        start_time = time.time()
        
        response = await call_next(request)
        
        # è®°å½•è¯·æ±‚ä¿¡æ¯
        process_time = (time.time() - start_time) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
        
        request_info = {
            "timestamp": time.time(),
            "method": request.method,
            "endpoint": request.url.path,
            "status_code": response.status_code,
            "response_time": round(process_time, 2)
        }
        
        add_request_metric(request_info)
        
        return response
    
    
    # æ·»åŠ å¥åº·æ£€æŸ¥ç«¯ç‚¹
    @app.get("/healthz")
    def healthz():
        """Kubernetes å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
        cuda_available = torch.cuda.is_available()
        model_loaded = MODEL is not None
        
        status = "ok" if model_loaded else "degraded"
        
        return {
            "status": status,
            "cuda": cuda_available,
            "model_loaded": model_loaded,
            "timestamp": time.time()
        }
    
    # æ·»åŠ  Prometheus ç›‘æ§ç«¯ç‚¹
    try:
        from prometheus_fastapi_instrumentator import Instrumentator
        instrumentator = Instrumentator()
        instrumentator.instrument(app)
        instrumentator.expose(app, endpoint="/metrics")
        print("ğŸ“Š Prometheus ç›‘æ§å·²å¯ç”¨")
    except ImportError:
        print("âš ï¸ prometheus_fastapi_instrumentator æœªå®‰è£…ï¼Œè·³è¿‡ç›‘æ§ç«¯ç‚¹")
    except Exception as e:
        print(f"âš ï¸ Prometheus ç›‘æ§è®¾ç½®å¤±è´¥: {e}")
    
    app.include_router(welcome_router)
    app.include_router(health_router)
    app.include_router(analyze_router, prefix="/analyze")
    app.include_router(convert_router, prefix="/convert")
    app.include_router(monitoring_router)
    
    # æŒ‚è½½é™æ€æ–‡ä»¶ç›®å½•
    app.mount("/static", StaticFiles(directory="static"), name="static")
    
    return app


app = create_app()


